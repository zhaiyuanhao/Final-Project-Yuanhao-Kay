[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Final Project: NYC Property Sales Predictor",
    "section": "",
    "text": "Our project explores the housing price trend in New York City, attempting to understanding what factors affect the sale prices most and developing a model that could effectively predict sale prices. We obtained the property sale data from the NYC Open Data using API. A quick exploration of the dataset informs that the average sale price per unit is around 400. We expected that housing prices is likely to be influenced by the safety level of the area that housing is located. Thus, we obtained the New York Policy Department’s arrest data. We also included conventional factors in the Census dataset, including total population, total housing units, mean travel time to work, median household income, total households, and people in labor force, which we believe could depict the demographic status of a specific area.\n\n\n\n\n\n\nImportant\n\n\n\nThe code for this Final Project is hosted on our course’s GitHub page: https://github.com/zhaiyuanhao/Final-Project-Yuanhao-Kay.git."
  },
  {
    "objectID": "index.html#background-and-exploratory-analysis",
    "href": "index.html#background-and-exploratory-analysis",
    "title": "Final Project: NYC Property Sales Predictor",
    "section": "",
    "text": "Our project explores the housing price trend in New York City, attempting to understanding what factors affect the sale prices most and developing a model that could effectively predict sale prices. We obtained the property sale data from the NYC Open Data using API. A quick exploration of the dataset informs that the average sale price per unit is around 400. We expected that housing prices is likely to be influenced by the safety level of the area that housing is located. Thus, we obtained the New York Policy Department’s arrest data. We also included conventional factors in the Census dataset, including total population, total housing units, mean travel time to work, median household income, total households, and people in labor force, which we believe could depict the demographic status of a specific area.\n\n\n\n\n\n\nImportant\n\n\n\nThe code for this Final Project is hosted on our course’s GitHub page: https://github.com/zhaiyuanhao/Final-Project-Yuanhao-Kay.git."
  },
  {
    "objectID": "index.html#our-data-source",
    "href": "index.html#our-data-source",
    "title": "Final Project: NYC Property Sales Predictor",
    "section": "Our Data Source",
    "text": "Our Data Source\n\nAnnualized Sales Update\nAnnualized Sales files display yearly sales information of properties sold in New York City. These files also have information such as neighborhood, building type, square footage and other data. You can find neighborhood and citywide sales data here starting with 2007. You can also find Annualized Sales files here starting with 2003 when sales data was first listed on the public record.\nNYC Citywide Annualized Calendar Sales Update\n\n\n2020 Census Tracts - Tabular\n2020 Census Tracts from the US Census for New York City. These boundary files are derived from the US Census Bureau’s TIGER data products and have been geographically modified to fit the New York City base map. All previously released versions of this data are available at BYTES of the BIG APPLE- Archive.\nNYC 2020 census tract\n\n\nNYPD Arrest Data (Year to Date)\nThis is a breakdown of every arrest effected in NYC by the NYPD during the current year. This data is manually extracted every quarter and reviewed by the Office of Management Analysis and Planning. Each record represents an arrest effected in NYC by the NYPD and includes information about the type of crime, the location and time of enforcement. In addition, information related to suspect demographics is also included. This data can be used by the public to explore the nature of police enforcement activity. Please refer to the attached data footnotes for additional information about this dataset.\nNYPD Arrest Data (Year to Date)"
  },
  {
    "objectID": "index.html#method",
    "href": "index.html#method",
    "title": "Final Project: NYC Property Sales Predictor",
    "section": "Method",
    "text": "Method\nWe chose Random Forest instead of traditional regression model because of the possible non-linear relationship embedded in our features and also because it could effectively reduce the risk of overfitting."
  },
  {
    "objectID": "index.html#author",
    "href": "index.html#author",
    "title": "Final Project: NYC Property Sales Predictor",
    "section": "Author",
    "text": "Author\n\nYuanhao Zhai\nKay Li"
  },
  {
    "objectID": "analysis/Final_Assignment.html",
    "href": "analysis/Final_Assignment.html",
    "title": "Final Assignment",
    "section": "",
    "text": "Introduction: to understand the impacts of the selected variables on housing prices in New York City, we first develop a model trained by the historical data of property sale price data in 2020. We include eight independent variables drawn from three different datasets, including total population, total housing units, people in labor force, travel time, median household income, total household, offense description for the area, building class category. To develop the model using historical data, we first split the 2020 sale data into the train and test datasets. We then use GridSearchCV to perform a k-fold cross validation that optimize at least 2 hyperparameters of the Random Forest Regressor.\n\n\nYuanhao Zhai, Kaye Li\n\n\n\n\nData is collected through a means more sophisticated than downloading (e.g. scraping, API)\nIt combines data collected from 3 or more different sources.\nThe analysis of the data is reasonably complex, involving multiple steps (geospatial joins/operations, data shaping, data frame operations, etc).\nYou use an osmnx or pandana to perform an analysis of street network data\nYou use scikit-learn to perform a clustering analysis.\nYou perform a machine learning analysis with scikit-learn as part of the analysis.\nThe project includes multiple interactive visualizations that include a significant interactive component (cross-filtering, interactive widgets, etc)\n\n\n\nCode\n#import the essential packages\n#base packages\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\n\n# Plotting packages\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport holoviews as hv\nimport hvplot.pandas\n\n# Sodapy API packages\nimport requests\nfrom sodapy import Socrata\n\n# Set a Random Seed\nnp.random.seed(42)\npd.options.display.max_columns = 999"
  },
  {
    "objectID": "analysis/Final_Assignment.html#prediction-of-property-saling-price-in-new-york-city-using-sklearn",
    "href": "analysis/Final_Assignment.html#prediction-of-property-saling-price-in-new-york-city-using-sklearn",
    "title": "Final Assignment",
    "section": "",
    "text": "Introduction: to understand the impacts of the selected variables on housing prices in New York City, we first develop a model trained by the historical data of property sale price data in 2020. We include eight independent variables drawn from three different datasets, including total population, total housing units, people in labor force, travel time, median household income, total household, offense description for the area, building class category. To develop the model using historical data, we first split the 2020 sale data into the train and test datasets. We then use GridSearchCV to perform a k-fold cross validation that optimize at least 2 hyperparameters of the Random Forest Regressor.\n\n\nYuanhao Zhai, Kaye Li\n\n\n\n\nData is collected through a means more sophisticated than downloading (e.g. scraping, API)\nIt combines data collected from 3 or more different sources.\nThe analysis of the data is reasonably complex, involving multiple steps (geospatial joins/operations, data shaping, data frame operations, etc).\nYou use an osmnx or pandana to perform an analysis of street network data\nYou use scikit-learn to perform a clustering analysis.\nYou perform a machine learning analysis with scikit-learn as part of the analysis.\nThe project includes multiple interactive visualizations that include a significant interactive component (cross-filtering, interactive widgets, etc)\n\n\n\nCode\n#import the essential packages\n#base packages\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\n\n# Plotting packages\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport holoviews as hv\nimport hvplot.pandas\n\n# Sodapy API packages\nimport requests\nfrom sodapy import Socrata\n\n# Set a Random Seed\nnp.random.seed(42)\npd.options.display.max_columns = 999"
  },
  {
    "objectID": "analysis/Final_Assignment.html#part-1-collecting-data-using-api",
    "href": "analysis/Final_Assignment.html#part-1-collecting-data-using-api",
    "title": "Final Assignment",
    "section": "Part 1: Collecting Data using API",
    "text": "Part 1: Collecting Data using API\nData Source:\nNYC Citywide Annualized Calendar Sales Update\nNYC 2020 census tract\nNYPD Arrest Data (Year to Date)\n\n1.1 Get the Property Saling data\nTo get the Property Saling Data from the NYC OpenData, We use the Socrata API to link the database.\n\n\nCode\nclient = Socrata(\"data.cityofnewyork.us\",\n                  \"6xHCd7htGtLFFnGXy6R9LdnXB\",\n                  username=\"zyuanhao@upenn.edu\",\n                  password=\"ZYHtt-0325\")\n\n\nGet the property saling price data from the NYC Open Data using Socrata API.\n\nproperty_sales = client.get_all(\"w2pb-icbu\")\n\n# Convert to pandas DataFrame\nprosal_df = pd.DataFrame.from_records(property_sales)\n\n\n# clean the raw saling price data, drop all NA data\nprosal_clean = prosal_df.drop(columns=['apartment_number','census_tract_2020','nta_code']).dropna()\n\n# convert the str data to float64 data\nprosal_clean['sale_price'] = pd.to_numeric(prosal_clean['sale_price'], errors='coerce')\nprosal_clean['gross_square_feet'] = prosal_clean['gross_square_feet'].replace(',', '', regex=True)\nprosal_clean['gross_square_feet'] = pd.to_numeric(prosal_clean['gross_square_feet'], errors='coerce')\n\n# drop the extreme data(sale price&gt;10000, gross square feet&lt;30)\nprosal_filtered = prosal_clean[(prosal_clean['sale_price'] &gt; 10000) & (prosal_clean['gross_square_feet'] &gt; 30)]\n\n# convert df data to geodataframe with crs: 4326\nprosal_clean_geo = gpd.GeoDataFrame(\n    prosal_filtered, geometry=gpd.points_from_xy(prosal_filtered.longitude, prosal_filtered.latitude), crs=\"EPSG:4326\"\n)\n\nTo better compare the property price we have to get the sale price per square feet.\n\nprosal_clean_geo['unit_sale_price'] = prosal_clean_geo['sale_price'] / prosal_clean_geo['gross_square_feet']\nprosal_clean_geo = prosal_clean_geo.dropna()\nprosal_clean_geo.head()\n\n#clean the extrame data\nQ1 =  prosal_clean_geo['unit_sale_price'].quantile(0.25)\nQ3 =  prosal_clean_geo['unit_sale_price'].quantile(0.75)\nIQR = Q3 - Q1\n\nlower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\nprosal_last_geo = prosal_clean_geo[(prosal_clean_geo['unit_sale_price'] &gt; lower) & (prosal_clean_geo['unit_sale_price'] &lt; upper)]\nprosal_last_geo.shape\n\n(162890, 29)\n\n\nNow, Let’s draw a box plot to explore the data\n\n\nCode\n# draw a box plot to explore the data\nplt.boxplot(prosal_last_geo['unit_sale_price'])\nplt.show()\n\n\n\n\n\nFrom the plot above, we can see that average price of property is around $400.\nAnd we can also draw a hitogram plot to see the distribution of the data.\n\n\nCode\nplt.hist(prosal_last_geo['unit_sale_price'], bins=25, edgecolor='black')\n\nplt.title('Property Price Per Square Feet')\nplt.xlabel('price per square feet')\nplt.ylabel('count')\n\nplt.show()\n\n\n\n\n\nMost of the price is between $200 to $600.\n\n\n1.2 Get the Public Safety Data\nTo further explain what fator contribute to the property price, we will collect the public safety data by using the NYPD Arrest data, this is a data with the catogory of crime and exact geographic position of crimes.\n\n# get the NYPD Arrest Data (Year to Date) \nNYPD_arrest = client.get_all(\"uip8-fykc\")\n\n# Convert to pandas DataFrame\npublic_safe = pd.DataFrame.from_records(NYPD_arrest)\n\n\n# Convert the dataframe to Geodataframe and drop the NA data.\nsafe_geo = gpd.GeoDataFrame(\n    public_safe, geometry=gpd.points_from_xy(public_safe.longitude, public_safe.latitude), crs=\"EPSG:4326\"\n).drop(columns=['geocoded_column']).dropna()\nsafe_geo.head()\n\n\n\n\n\n\n\n\narrest_key\narrest_date\npd_cd\npd_desc\nky_cd\nofns_desc\nlaw_code\nlaw_cat_cd\narrest_boro\narrest_precinct\njurisdiction_code\nage_group\nperp_sex\nperp_race\nx_coord_cd\ny_coord_cd\nlatitude\nlongitude\n:@computed_region_f5dn_yrer\n:@computed_region_yeji_bk3q\n:@computed_region_92fq_4b7q\n:@computed_region_sbqj_enih\n:@computed_region_efsh_h5xi\ngeometry\n\n\n\n\n0\n261209118\n2023-01-01T00:00:00.000\n109\nASSAULT 2,1,UNCLASSIFIED\n106\nFELONY ASSAULT\nPL 1200501\nF\nK\n77\n0\n45-64\nF\nBLACK\n999335\n186085\n40.677426\n-73.945615\n16\n2\n49\n49\n17618\nPOINT (-73.94562 40.67743)\n\n\n1\n262984267\n2023-02-03T00:00:00.000\n515\nCONTROLLED SUBSTANCE,SALE 3\n117\nDANGEROUS DRUGS\nPL 2203901\nF\nK\n73\n0\n25-44\nM\nBLACK\n1009318\n178259\n40.655923\n-73.90965\n55\n2\n25\n46\n17614\nPOINT (-73.90965 40.65592)\n\n\n2\n263664549\n2023-02-15T00:00:00.000\n105\nSTRANGULATION 1ST\n106\nFELONY ASSAULT\nPL 1211200\nF\nK\n62\n0\n25-44\nM\nWHITE\n982272\n158771\n40.602468\n-74.00712\n1\n2\n44\n37\n17616\nPOINT (-74.00712 40.60247)\n\n\n3\n261345231\n2023-01-04T00:00:00.000\n105\nSTRANGULATION 1ST\n106\nFELONY ASSAULT\nPL 1211200\nF\nM\n32\n0\n25-44\nM\nBLACK\n999899\n238684\n40.821797\n-73.943457\n18\n4\n36\n20\n12427\nPOINT (-73.94346 40.82180)\n\n\n4\n263536618\n2023-02-13T00:00:00.000\n109\nASSAULT 2,1,UNCLASSIFIED\n106\nFELONY ASSAULT\nPL 12005WX\nF\nK\n71\n0\n25-44\nM\nBLACK\n1001437\n183080\n40.669175\n-73.938042\n16\n2\n48\n49\n17615\nPOINT (-73.93804 40.66918)\n\n\n\n\n\n\n\n\n\nCode\nplt.figure(figsize=(5,10))\nplt.hist(safe_geo['ofns_desc'],  orientation='horizontal', edgecolor='black')\n\n\n(array([6.0572e+04, 4.7617e+04, 1.4415e+04, 1.5298e+04, 1.8410e+04,\n        8.8820e+03, 2.5980e+03, 3.5700e+02, 2.2800e+02, 5.3000e+01]),\n array([ 0. ,  6.1, 12.2, 18.3, 24.4, 30.5, 36.6, 42.7, 48.8, 54.9, 61. ]),\n &lt;BarContainer object of 10 artists&gt;)\n\n\n\n\n\n\n\n1.3 Get the census tract data\nAnd besides the public safety, We assume that the population, household income, labor force, traffic time will also have effect on sale price, so we decide to get the data relate to those topic.\n\n# get the census tract data available\nimport cenpy\n\navailable = cenpy.explorer.available()\n\nC:\\Users\\zhaiy\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\libpysal\\cg\\alpha_shapes.py:39: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def nb_dist(x, y):\nC:\\Users\\zhaiy\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\libpysal\\cg\\alpha_shapes.py:165: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def get_faces(triangle):\nC:\\Users\\zhaiy\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\libpysal\\cg\\alpha_shapes.py:199: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def build_faces(faces, triangles_is, num_triangles, num_faces_single):\nC:\\Users\\zhaiy\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\libpysal\\cg\\alpha_shapes.py:261: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def nb_mask_faces(mask, faces):\n\n\n\n#we will use the data from 2020, by American Community Survey estimates\nacs = cenpy.remote.APIConnection(\"ACSDP5Y2020\")\n\n#explore the data profile included in this database \nacs.variables.head()\n\n\n\n\n\n\n\n\nlabel\nconcept\npredicateType\ngroup\nlimit\npredicateOnly\nhasGeoCollectionSupport\nattributes\nrequired\n\n\n\n\nfor\nCensus API FIPS 'for' clause\nCensus API Geography Specification\nfips-for\nN/A\n0\nTrue\nNaN\nNaN\nNaN\n\n\nin\nCensus API FIPS 'in' clause\nCensus API Geography Specification\nfips-in\nN/A\n0\nTrue\nNaN\nNaN\nNaN\n\n\nucgid\nUniform Census Geography Identifier clause\nCensus API Geography Specification\nucgid\nN/A\n0\nTrue\nTrue\nNaN\nNaN\n\n\nDP02_0126E\nEstimate!!ANCESTRY!!Total population!!Arab\nSELECTED SOCIAL CHARACTERISTICS IN THE UNITED ...\nint\nDP02\n0\nNaN\nNaN\nDP02_0126EA,DP02_0126M,DP02_0126MA\nNaN\n\n\nDP05_0050PE\nPercent!!RACE!!Total population!!One race!!Asi...\nACS DEMOGRAPHIC AND HOUSING ESTIMATES\nfloat\nDP05\n0\nNaN\nNaN\nDP05_0050PEA,DP05_0050PM,DP05_0050PMA\nNaN\n\n\n\n\n\n\n\n\n\nCode\npd.options.display.max_rows = 9999 \npd.options.display.max_colwidth = 200\n\n\n\nvariables = [\n   \"NAME\",\n   \"DP05_0001E\", #Total population\n   \"DP05_0086E\", #Total Housing Units\n   \"DP03_0002E\", #In Labor Force\n   \"DP03_0025E\", #Mean travel time to work (minutes)\n   \"DP03_0062E\", #Median household income (dollars)\n   \"DP02_0001E\", #Total households\n]\n\nTips\nNew York City is composed of 5 boroughs, with each borough also its own county. Manhattan is in New York County, Brooklyn is in Kings County, Queens is in Queens County, the Bronx is in Bronx County, and Staten Island is in Richmond County. The counties and boroughs of New York City are coterminous.\n\n# First, get the NY County Data.\nnyc_demo_data = acs.query(\n    cols=variables,\n    geo_unit=\"tract:*\",\n    geo_filter={\"state\": \"36\", \"county\": \"061\"},\n)\n\n\n# Then, Get the data from 4 other Counties\ncounties = [('36', '005'),('36','047'),('36','081'),('36','085')]  # Replace with actual FIPS codes\n\nfor state, county in counties:\n    new_data = acs.query(cols=variables, geo_unit='tract', geo_filter={'state': state, 'county': county})\n    nyc_demo_data = nyc_demo_data.append(new_data, ignore_index=True)\n\nC:\\Users\\zhaiy\\AppData\\Local\\Temp\\ipykernel_8424\\2929721321.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  nyc_demo_data = nyc_demo_data.append(new_data, ignore_index=True)\nC:\\Users\\zhaiy\\AppData\\Local\\Temp\\ipykernel_8424\\2929721321.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  nyc_demo_data = nyc_demo_data.append(new_data, ignore_index=True)\nC:\\Users\\zhaiy\\AppData\\Local\\Temp\\ipykernel_8424\\2929721321.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  nyc_demo_data = nyc_demo_data.append(new_data, ignore_index=True)\nC:\\Users\\zhaiy\\AppData\\Local\\Temp\\ipykernel_8424\\2929721321.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  nyc_demo_data = nyc_demo_data.append(new_data, ignore_index=True)\n\n\n\n# Rename the data to our topic\nnyc_census = nyc_demo_data.rename(columns={\"DP05_0001E\": \"Total_Population\",\n                              \"DP05_0086E\": \"Total Housing Units\",\n                              \"DP03_0002E\":\"In Labor Force\",\n                              \"DP03_0025E\":\"Travel_Time\", \n                              \"DP03_0062E\":\"Median_HH_Income\",\n                              \"DP02_0001E\":\"Total_HH\"})\n\nnyc_census['GEOID'] = nyc_census['state'] + nyc_census['county'] + nyc_census['tract']\nnyc_census.head()\n\n\n\n\n\n\n\n\nNAME\nTotal_Population\nTotal Housing Units\nIn Labor Force\nTravel_Time\nMedian_HH_Income\nTotal_HH\nstate\ncounty\ntract\nGEOID\n\n\n\n\n0\nCensus Tract 165, New York County, New York\n6674\n3841\n3954\n32.9\n184691\n3176\n36\n061\n016500\n36061016500\n\n\n1\nCensus Tract 166, New York County, New York\n6002\n3279\n2953\n33.0\n47778\n2796\n36\n061\n016600\n36061016600\n\n\n2\nCensus Tract 167, New York County, New York\n6058\n3804\n3616\n30.6\n203711\n2969\n36\n061\n016700\n36061016700\n\n\n3\nCensus Tract 168, New York County, New York\n5189\n2102\n1561\n44.3\n27222\n1774\n36\n061\n016800\n36061016800\n\n\n4\nCensus Tract 169, New York County, New York\n8272\n5016\n5033\n31.0\n131097\n3949\n36\n061\n016900\n36061016900\n\n\n\n\n\n\n\n\nlen(nyc_census) # We have 2327 Census Tracts in total.\n\n2327\n\n\n\n\nCode\n# Then we will get the polygon of our census tracts in order to merge data with values\nimport pygris\n\n\n\nnyc_tracts = pygris.tracts(\n    state=\"36\", county=\"061\", year=2020\n)\n\nfor state, county in counties:\n    new_tracts = pygris.tracts(\n    state=state, county=county, year=2020\n)\n    nyc_tracts = nyc_tracts.append(new_tracts, ignore_index=True)\n\nC:\\Users\\zhaiy\\AppData\\Local\\Temp\\ipykernel_8424\\405300660.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  nyc_tracts = nyc_tracts.append(new_tracts, ignore_index=True)\nC:\\Users\\zhaiy\\AppData\\Local\\Temp\\ipykernel_8424\\405300660.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  nyc_tracts = nyc_tracts.append(new_tracts, ignore_index=True)\nC:\\Users\\zhaiy\\AppData\\Local\\Temp\\ipykernel_8424\\405300660.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  nyc_tracts = nyc_tracts.append(new_tracts, ignore_index=True)\nC:\\Users\\zhaiy\\AppData\\Local\\Temp\\ipykernel_8424\\405300660.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  nyc_tracts = nyc_tracts.append(new_tracts, ignore_index=True)\n\n\n\nnyc_tracts.head()\n\n\n\n\n\n\n\n\nSTATEFP\nCOUNTYFP\nTRACTCE\nGEOID\nNAME\nNAMELSAD\nMTFCC\nFUNCSTAT\nALAND\nAWATER\nINTPTLAT\nINTPTLON\ngeometry\n\n\n\n\n0\n36\n061\n001501\n36061001501\n15.01\nCensus Tract 15.01\nG5020\nS\n270812\n166085\n+40.7075653\n-074.0013991\nPOLYGON ((-74.00860 40.71139, -74.00835 40.71136, -74.00797 40.71145, -74.00809 40.71146, -74.00815 40.71148, -74.00820 40.71149, -74.00822 40.71152, -74.00823 40.71155, -74.00822 40.71158, -74.00...\n\n\n1\n36\n061\n001600\n36061001600\n16\nCensus Tract 16\nG5020\nS\n207381\n0\n+40.7159568\n-073.9932660\nPOLYGON ((-73.99750 40.71407, -73.99709 40.71462, -73.99681 40.71504, -73.99653 40.71547, -73.99606 40.71623, -73.99543 40.71728, -73.99481 40.71846, -73.99383 40.71814, -73.99309 40.71792, -73.99...\n\n\n2\n36\n061\n001800\n36061001800\n18\nCensus Tract 18\nG5020\nS\n222964\n0\n+40.7190464\n-073.9908407\nPOLYGON ((-73.99442 40.71939, -73.99438 40.71952, -73.99426 40.71978, -73.99403 40.72032, -73.99379 40.72094, -73.99367 40.72126, -73.99352 40.72163, -73.99273 40.72140, -73.99224 40.72125, -73.99...\n\n\n3\n36\n061\n002000\n36061002000\n20\nCensus Tract 20\nG5020\nS\n126280\n137883\n+40.7206299\n-073.9750259\nPOLYGON ((-73.97872 40.71998, -73.97823 40.72067, -73.97802 40.72097, -73.97779 40.72128, -73.97768 40.72142, -73.97736 40.72186, -73.97735 40.72189, -73.97689 40.72250, -73.97616 40.72219, -73.97...\n\n\n4\n36\n061\n002201\n36061002201\n22.01\nCensus Tract 22.01\nG5020\nS\n161668\n0\n+40.7191156\n-073.9818443\nPOLYGON ((-73.98448 40.72023, -73.98382 40.72147, -73.98300 40.72122, -73.98217 40.72097, -73.98131 40.72071, -73.97973 40.72023, -73.97875 40.71993, -73.97904 40.71939, -73.97942 40.71867, -73.97..."
  },
  {
    "objectID": "analysis/Final_Assignment.html#part-2-spatial-join-the-data-to-the-census-tract.",
    "href": "analysis/Final_Assignment.html#part-2-spatial-join-the-data-to-the-census-tract.",
    "title": "Final Assignment",
    "section": "Part 2: Spatial join the data to the census tract.",
    "text": "Part 2: Spatial join the data to the census tract.\nAnd take a look at the median housing price of different census tract.\n\nmerged_ct = pd.merge(nyc_tracts, nyc_census, on='GEOID', how='left')\nmerged_ct.head()\n\n\n\n\n\n\n\n\nSTATEFP\nCOUNTYFP\nTRACTCE\nGEOID\nNAME_x\nNAMELSAD\nMTFCC\nFUNCSTAT\nALAND\nAWATER\nINTPTLAT\nINTPTLON\ngeometry\nNAME_y\nTotal_Population\nTotal Housing Units\nIn Labor Force\nTravel_Time\nMedian_HH_Income\nTotal_HH\nstate\ncounty\ntract\n\n\n\n\n0\n36\n061\n001501\n36061001501\n15.01\nCensus Tract 15.01\nG5020\nS\n270812\n166085\n+40.7075653\n-074.0013991\nPOLYGON ((-74.00860 40.71139, -74.00835 40.71136, -74.00797 40.71145, -74.00809 40.71146, -74.00815 40.71148, -74.00820 40.71149, -74.00822 40.71152, -74.00823 40.71155, -74.00822 40.71158, -74.00...\nCensus Tract 15.01, New York County, New York\n8021\n4266\n4352\n25.5\n103102\n3720\n36\n061\n001501\n\n\n1\n36\n061\n001600\n36061001600\n16\nCensus Tract 16\nG5020\nS\n207381\n0\n+40.7159568\n-073.9932660\nPOLYGON ((-73.99750 40.71407, -73.99709 40.71462, -73.99681 40.71504, -73.99653 40.71547, -73.99606 40.71623, -73.99543 40.71728, -73.99481 40.71846, -73.99383 40.71814, -73.99309 40.71792, -73.99...\nCensus Tract 16, New York County, New York\n7504\n3448\n4271\n31.0\n60975\n3147\n36\n061\n001600\n\n\n2\n36\n061\n001800\n36061001800\n18\nCensus Tract 18\nG5020\nS\n222964\n0\n+40.7190464\n-073.9908407\nPOLYGON ((-73.99442 40.71939, -73.99438 40.71952, -73.99426 40.71978, -73.99403 40.72032, -73.99379 40.72094, -73.99367 40.72126, -73.99352 40.72163, -73.99273 40.72140, -73.99224 40.72125, -73.99...\nCensus Tract 18, New York County, New York\n7101\n3383\n3800\n28.0\n51480\n3095\n36\n061\n001800\n\n\n3\n36\n061\n002000\n36061002000\n20\nCensus Tract 20\nG5020\nS\n126280\n137883\n+40.7206299\n-073.9750259\nPOLYGON ((-73.97872 40.71998, -73.97823 40.72067, -73.97802 40.72097, -73.97779 40.72128, -73.97768 40.72142, -73.97736 40.72186, -73.97735 40.72189, -73.97689 40.72250, -73.97616 40.72219, -73.97...\nCensus Tract 20, New York County, New York\n4606\n2040\n1302\n37.7\n18750\n1964\n36\n061\n002000\n\n\n4\n36\n061\n002201\n36061002201\n22.01\nCensus Tract 22.01\nG5020\nS\n161668\n0\n+40.7191156\n-073.9818443\nPOLYGON ((-73.98448 40.72023, -73.98382 40.72147, -73.98300 40.72122, -73.98217 40.72097, -73.98131 40.72071, -73.97973 40.72023, -73.97875 40.71993, -73.97904 40.71939, -73.97942 40.71867, -73.97...\nCensus Tract 22.01, New York County, New York\n6372\n3165\n2759\n35.7\n25188\n2988\n36\n061\n002201\n\n\n\n\n\n\n\n\nlen(merged_ct)\n\n2327\n\n\nExplore the data by using a interactive map!\n\n\nCode\nmerged_ct.explore(\"Median_HH_Income\")\n\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\nCode\nmerged_ct = merged_ct.to_crs(epsg='4326')\n\n\n\nsafe_merged = gpd.sjoin(merged_ct, safe_geo, how='left', op='intersects')\nsafe_merged.head()\n\nC:\\Users\\zhaiy\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3448: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n  if await self.run_code(code, result, async_=asy):\n\n\n\n\n\n\n\n\n\nSTATEFP\nCOUNTYFP\nTRACTCE\nGEOID\nNAME_x\nNAMELSAD\nMTFCC\nFUNCSTAT\nALAND\nAWATER\nINTPTLAT\nINTPTLON\ngeometry\nNAME_y\nTotal_Population\nTotal Housing Units\nIn Labor Force\nTravel_Time\nMedian_HH_Income\nTotal_HH\nstate\ncounty\ntract\nindex_right\narrest_key\narrest_date\npd_cd\npd_desc\nky_cd\nofns_desc\nlaw_code\nlaw_cat_cd\narrest_boro\narrest_precinct\njurisdiction_code\nage_group\nperp_sex\nperp_race\nx_coord_cd\ny_coord_cd\nlatitude\nlongitude\n:@computed_region_f5dn_yrer\n:@computed_region_yeji_bk3q\n:@computed_region_92fq_4b7q\n:@computed_region_sbqj_enih\n:@computed_region_efsh_h5xi\n\n\n\n\n0\n36\n061\n001501\n36061001501\n15.01\nCensus Tract 15.01\nG5020\nS\n270812\n166085\n+40.7075653\n-074.0013991\nPOLYGON ((-74.00860 40.71139, -74.00835 40.71136, -74.00797 40.71145, -74.00809 40.71146, -74.00815 40.71148, -74.00820 40.71149, -74.00822 40.71152, -74.00823 40.71155, -74.00822 40.71158, -74.00...\nCensus Tract 15.01, New York County, New York\n8021\n4266\n4352\n25.5\n103102\n3720\n36\n061\n001501\n114437.0\n273573301\n2023-08-28T00:00:00.000\n494\nSTOLEN PROPERTY 2,1,POSSESSION\n111\nPOSSESSION OF STOLEN PROPERTY\nPL 1654501\nF\nM\n1\n0\n25-44\nM\nBLACK HISPANIC\n982722\n197618\n40.70909234324655\n-74.0055114103435\n56\n4\n32\n1\n13096\n\n\n0\n36\n061\n001501\n36061001501\n15.01\nCensus Tract 15.01\nG5020\nS\n270812\n166085\n+40.7075653\n-074.0013991\nPOLYGON ((-74.00860 40.71139, -74.00835 40.71136, -74.00797 40.71145, -74.00809 40.71146, -74.00815 40.71148, -74.00820 40.71149, -74.00822 40.71152, -74.00823 40.71155, -74.00822 40.71158, -74.00...\nCensus Tract 15.01, New York County, New York\n8021\n4266\n4352\n25.5\n103102\n3720\n36\n061\n001501\n71325.0\n268056743\n2023-05-10T00:00:00.000\n109\nASSAULT 2,1,UNCLASSIFIED\n106\nFELONY ASSAULT\nPL 1200501\nF\nM\n1\n0\n65+\nF\nASIAN / PACIFIC ISLANDER\n982593\n197702\n40.709325\n-74.005974\n56\n4\n32\n1\n13096\n\n\n0\n36\n061\n001501\n36061001501\n15.01\nCensus Tract 15.01\nG5020\nS\n270812\n166085\n+40.7075653\n-074.0013991\nPOLYGON ((-74.00860 40.71139, -74.00835 40.71136, -74.00797 40.71145, -74.00809 40.71146, -74.00815 40.71148, -74.00820 40.71149, -74.00822 40.71152, -74.00823 40.71155, -74.00822 40.71158, -74.00...\nCensus Tract 15.01, New York County, New York\n8021\n4266\n4352\n25.5\n103102\n3720\n36\n061\n001501\n60714.0\n263536626\n2023-02-13T00:00:00.000\n339\nLARCENY,PETIT FROM OPEN AREAS,\n341\nPETIT LARCENY\nPL 1552500\nM\nM\n1\n0\n25-44\nF\nWHITE\n982593\n197702\n40.709325\n-74.005974\n56\n4\n32\n1\n13096\n\n\n0\n36\n061\n001501\n36061001501\n15.01\nCensus Tract 15.01\nG5020\nS\n270812\n166085\n+40.7075653\n-074.0013991\nPOLYGON ((-74.00860 40.71139, -74.00835 40.71136, -74.00797 40.71145, -74.00809 40.71146, -74.00815 40.71148, -74.00820 40.71149, -74.00822 40.71152, -74.00823 40.71155, -74.00822 40.71158, -74.00...\nCensus Tract 15.01, New York County, New York\n8021\n4266\n4352\n25.5\n103102\n3720\n36\n061\n001501\n6811.0\n266496509\n2023-04-11T00:00:00.000\n109\nASSAULT 2,1,UNCLASSIFIED\n106\nFELONY ASSAULT\nPL 1200502\nF\nM\n1\n0\n25-44\nM\nBLACK\n982380\n197844\n40.709715\n-74.006744\n56\n4\n32\n1\n13096\n\n\n0\n36\n061\n001501\n36061001501\n15.01\nCensus Tract 15.01\nG5020\nS\n270812\n166085\n+40.7075653\n-074.0013991\nPOLYGON ((-74.00860 40.71139, -74.00835 40.71136, -74.00797 40.71145, -74.00809 40.71146, -74.00815 40.71148, -74.00820 40.71149, -74.00822 40.71152, -74.00823 40.71155, -74.00822 40.71158, -74.00...\nCensus Tract 15.01, New York County, New York\n8021\n4266\n4352\n25.5\n103102\n3720\n36\n061\n001501\n69172.0\n271435118\n2023-07-17T00:00:00.000\n339\nLARCENY,PETIT FROM OPEN AREAS,\n341\nPETIT LARCENY\nPL 1552500\nM\nM\n1\n0\n25-44\nM\nBLACK HISPANIC\n982380\n197844\n40.709715\n-74.006744\n56\n4\n32\n1\n13096\n\n\n\n\n\n\n\n\ncount_values = safe_merged.groupby('GEOID')['ofns_desc'].count()\n\nmerged_ct = merged_ct.merge(count_values, left_on='GEOID', right_index=True)\n\n\nsales_census = gpd.sjoin(prosal_last_geo, merged_ct, how='left', op='intersects').drop(columns = ['index_right'])\nsales_census.head()\n\nC:\\Users\\zhaiy\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3448: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n  if await self.run_code(code, result, async_=asy):\n\n\n\n\n\n\n\n\n\nborough\nneighborhood\nbuilding_class_category\ntax_class_as_of_final_roll\nblock\nlot\nbuilding_class_as_of_final\naddress\nzip_code\nresidential_units\ncommercial_units\ntotal_units\nland_square_feet\ngross_square_feet\nyear_built\ntax_class_at_time_of_sale\nbuilding_class_at_time_of\nsale_price\nsale_date\nlatitude\nlongitude\ncommunity_board\ncouncil_district\ncensus_tract\nbin\nbbl\nnta\ngeometry\nunit_sale_price\nSTATEFP\nCOUNTYFP\nTRACTCE\nGEOID\nNAME_x\nNAMELSAD\nMTFCC\nFUNCSTAT\nALAND\nAWATER\nINTPTLAT\nINTPTLON\nNAME_y\nTotal_Population\nTotal Housing Units\nIn Labor Force\nTravel_Time\nMedian_HH_Income\nTotal_HH\nstate\ncounty\ntract\nofns_desc\n\n\n\n\n5\n1\nCHELSEA\n21 OFFICE BUILDINGS\n4\n802\n75\nO6\n158 WEST 27 STREET\n10001\n0\n14\n14\n8,305\n108000.0\n1913\n4\nO6\n99350000.0\n2019-10-24T00:00:00.000\n40.746089\n-73.992576\n105\n3\n95\n1015055\n1008020075\nMidtown-Midtown South\nPOINT (-73.99258 40.74609)\n919.907407\n36\n061\n009500\n36061009500\n95\nCensus Tract 95\nG5020\nS\n171964.0\n0.0\n+40.7472363\n-073.9933578\nCensus Tract 95, New York County, New York\n2985\n1393\n1547\n22.7\n136944\n1148\n36\n061\n009500\n101.0\n\n\n6\n1\nCHELSEA\n21 OFFICE BUILDINGS\n4\n803\n4\nO4\n307 7 AVENUE\n10001\n0\n194\n194\n10,225\n197612.0\n1926\n4\nO4\n115000000.0\n2019-10-17T00:00:00.000\n40.746869\n-73.993616\n105\n3\n95\n1015061\n1008030004\nMidtown-Midtown South\nPOINT (-73.99362 40.74687)\n581.948465\n36\n061\n009500\n36061009500\n95\nCensus Tract 95\nG5020\nS\n171964.0\n0.0\n+40.7472363\n-073.9933578\nCensus Tract 95, New York County, New York\n2985\n1393\n1547\n22.7\n136944\n1148\n36\n061\n009500\n101.0\n\n\n8\n1\nCHELSEA\n22 STORE BUILDINGS\n4\n772\n72\nK7\n250 WEST 23RD STREET\n10011\n0\n1\n1\n4,938\n15716.0\n1948\n4\nK7\n14500000.0\n2019-09-05T00:00:00.000\n40.744698\n-73.997091\n104\n3\n91\n1014135\n1007720072\nHudson Yards-Chelsea-Flatiron-Union Square\nPOINT (-73.99709 40.74470)\n922.626623\n36\n061\n009100\n36061009100\n91\nCensus Tract 91\nG5020\nS\n179098.0\n0.0\n+40.7447178\n-073.9951959\nCensus Tract 91, New York County, New York\n6046\n4145\n4450\n22.3\n152946\n3524\n36\n061\n009100\n118.0\n\n\n11\n1\nCHELSEA\n23 LOFT BUILDINGS\n4\n799\n67\nL1\n148 WEST 24TH STREET, 4 FL\n10011\n0\n15\n15\n4,937\n55923.0\n1910\n4\nL1\n4500000.0\n2019-02-28T00:00:00.000\n40.744149\n-73.993721\n104\n3\n91\n1014966\n1007990067\nHudson Yards-Chelsea-Flatiron-Union Square\nPOINT (-73.99372 40.74415)\n80.467786\n36\n061\n009100\n36061009100\n91\nCensus Tract 91\nG5020\nS\n179098.0\n0.0\n+40.7447178\n-073.9951959\nCensus Tract 91, New York County, New York\n6046\n4145\n4450\n22.3\n152946\n3524\n36\n061\n009100\n118.0\n\n\n14\n1\nCHELSEA\n30 WAREHOUSES\n4\n794\n9\nE9\n157 WEST 18TH STREET\n10011\n0\n1\n1\n3,620\n23800.0\n1906\n4\nE9\n23200000.0\n2019-02-20T00:00:00.000\n40.740526\n-73.996575\n104\n3\n87\n1014713\n1007940009\nHudson Yards-Chelsea-Flatiron-Union Square\nPOINT (-73.99658 40.74053)\n974.789916\n36\n061\n008700\n36061008700\n87\nCensus Tract 87\nG5020\nS\n165443.0\n0.0\n+40.7422439\n-073.9969962\nCensus Tract 87, New York County, New York\n6347\n4208\n4855\n23.0\n152774\n3951\n36\n061\n008700\n631.0\n\n\n\n\n\n\n\n\nsales_census = sales_census.dropna()\nlen(sales_census)\n\n162879"
  },
  {
    "objectID": "analysis/Final_Assignment.html#part-3-sklearn-train-a-random-forest-on-property-sales",
    "href": "analysis/Final_Assignment.html#part-3-sklearn-train-a-random-forest-on-property-sales",
    "title": "Final Assignment",
    "section": "Part 3: SKlearn Train a Random Forest on Property Sales",
    "text": "Part 3: SKlearn Train a Random Forest on Property Sales\nThen, We get all the data we need to train a predict model, we can start training right now!\n\n\nCode\n# Models\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Model selection\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n\n# Pipelines\nfrom sklearn.pipeline import make_pipeline\n\n# Preprocessing\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\n\n\n\n3.1 set a pipeline include all variables\n\n\nCode\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\n\n\n# Numerical columns\nnum_cols = [\n    \"Total_Population\",\n    \"Total Housing Units\",\n    \"In Labor Force\",\n    \"Travel_Time\",\n    \"Median_HH_Income\",\n    \"Total_HH\",\n    \"ofns_desc\",\n]\n\n# Categorical columns\ncat_cols = [\n    \"building_class_category\", \n]\n\n\n# Set up the column transformer with two transformers\n# ----&gt; Scale the numerical columns\n# ----&gt; One-hot encode the categorical columns\n\ntransformer = ColumnTransformer(\n    transformers=[\n        (\"num\", StandardScaler(), num_cols),\n        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n    ]\n)\n\n\n# Initialize the pipeline\n# NOTE: only use 20 estimators here so it will run in a reasonable time\npipe = make_pipeline(\n    transformer, RandomForestRegressor(n_estimators=20, random_state=42)\n)\n\n\n\n3.2 Split 30% & 70%\n\n# Split the data 70/30\ntrain_set, test_set = train_test_split(sales_census, \n                                       test_size=0.3, \n                                       random_state=42)\n\n# the target labels: log of sale price\ny_train = np.log(train_set[\"unit_sale_price\"])\ny_test = np.log(test_set[\"unit_sale_price\"])\nx_train = train_set[\n   [ \"Total_Population\",\n    \"Total Housing Units\",\n    \"In Labor Force\",\n    \"Travel_Time\",\n    \"Median_HH_Income\",\n    \"Total_HH\",\n    \"ofns_desc\",\n    \"building_class_category\",]\n]\nx_test = test_set[\n   [\"Total_Population\",\n    \"Total Housing Units\",\n    \"In Labor Force\",\n    \"Travel_Time\",\n    \"Median_HH_Income\",\n    \"Total_HH\",\n    \"ofns_desc\",\n    \"building_class_category\",]\n]\n\n\n# Fit the training set\npipe.fit(train_set, y_train);\n\n\n# What's the test score?\npipe.score(test_set, y_test)\n\n0.4906609622139816\n\n\n\n\n3.3 Use GridSearchCV to perform a k-fold cross validation that optimize at least 2 hyperparameters of the RandomForestRegressor.\n\nfrom sklearn.model_selection import GridSearchCV\n\n\nfrom sklearn.pipeline import Pipeline\n# Create our regression pipeline\npipe2 = Pipeline(steps=[('preprocessor', transformer),\n                              ('regressor', RandomForestRegressor())])\npipe2\n\nPipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('num', StandardScaler(),\n                                                  ['Total_Population',\n                                                   'Total Housing Units',\n                                                   'In Labor Force',\n                                                   'Travel_Time',\n                                                   'Median_HH_Income',\n                                                   'Total_HH', 'ofns_desc']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore'),\n                                                  ['building_class_category'])])),\n                ('regressor', RandomForestRegressor())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('num', StandardScaler(),\n                                                  ['Total_Population',\n                                                   'Total Housing Units',\n                                                   'In Labor Force',\n                                                   'Travel_Time',\n                                                   'Median_HH_Income',\n                                                   'Total_HH', 'ofns_desc']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore'),\n                                                  ['building_class_category'])])),\n                ('regressor', RandomForestRegressor())])preprocessor: ColumnTransformerColumnTransformer(transformers=[('num', StandardScaler(),\n                                 ['Total_Population', 'Total Housing Units',\n                                  'In Labor Force', 'Travel_Time',\n                                  'Median_HH_Income', 'Total_HH',\n                                  'ofns_desc']),\n                                ('cat', OneHotEncoder(handle_unknown='ignore'),\n                                 ['building_class_category'])])num['Total_Population', 'Total Housing Units', 'In Labor Force', 'Travel_Time', 'Median_HH_Income', 'Total_HH', 'ofns_desc']StandardScalerStandardScaler()cat['building_class_category']OneHotEncoderOneHotEncoder(handle_unknown='ignore')RandomForestRegressorRandomForestRegressor()\n\n\n\npipe2.named_steps\n\n{'preprocessor': ColumnTransformer(transformers=[('num', StandardScaler(),\n                                  ['Total_Population', 'Total Housing Units',\n                                   'In Labor Force', 'Travel_Time',\n                                   'Median_HH_Income', 'Total_HH',\n                                   'ofns_desc']),\n                                 ('cat', OneHotEncoder(handle_unknown='ignore'),\n                                  ['building_class_category'])]),\n 'regressor': RandomForestRegressor()}\n\n\n\nparam_grid = {\n    'regressor__n_estimators': [100, 200, 300],  \n    'regressor__max_depth': [None, 10, 20, 30],  \n    \n}\nparam_grid\n\n{'regressor__n_estimators': [100, 200, 300],\n 'regressor__max_depth': [None, 10, 20, 30]}\n\n\n\ngrid_search = GridSearchCV(pipe2, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\ngrid_search.fit(x_train, y_train)\n\nFitting 5 folds for each of 12 candidates, totalling 60 fits\n\n\nGridSearchCV(cv=5,\n             estimator=Pipeline(steps=[('preprocessor',\n                                        ColumnTransformer(transformers=[('num',\n                                                                         StandardScaler(),\n                                                                         ['Total_Population',\n                                                                          'Total '\n                                                                          'Housing '\n                                                                          'Units',\n                                                                          'In '\n                                                                          'Labor '\n                                                                          'Force',\n                                                                          'Travel_Time',\n                                                                          'Median_HH_Income',\n                                                                          'Total_HH',\n                                                                          'ofns_desc']),\n                                                                        ('cat',\n                                                                         OneHotEncoder(handle_unknown='ignore'),\n                                                                         ['building_class_category'])])),\n                                       ('regressor', RandomForestRegressor())]),\n             n_jobs=-1,\n             param_grid={'regressor__max_depth': [None, 10, 20, 30],\n                         'regressor__n_estimators': [100, 200, 300]},\n             scoring='neg_mean_squared_error', verbose=2)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCVGridSearchCV(cv=5,\n             estimator=Pipeline(steps=[('preprocessor',\n                                        ColumnTransformer(transformers=[('num',\n                                                                         StandardScaler(),\n                                                                         ['Total_Population',\n                                                                          'Total '\n                                                                          'Housing '\n                                                                          'Units',\n                                                                          'In '\n                                                                          'Labor '\n                                                                          'Force',\n                                                                          'Travel_Time',\n                                                                          'Median_HH_Income',\n                                                                          'Total_HH',\n                                                                          'ofns_desc']),\n                                                                        ('cat',\n                                                                         OneHotEncoder(handle_unknown='ignore'),\n                                                                         ['building_class_category'])])),\n                                       ('regressor', RandomForestRegressor())]),\n             n_jobs=-1,\n             param_grid={'regressor__max_depth': [None, 10, 20, 30],\n                         'regressor__n_estimators': [100, 200, 300]},\n             scoring='neg_mean_squared_error', verbose=2)estimator: PipelinePipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('num', StandardScaler(),\n                                                  ['Total_Population',\n                                                   'Total Housing Units',\n                                                   'In Labor Force',\n                                                   'Travel_Time',\n                                                   'Median_HH_Income',\n                                                   'Total_HH', 'ofns_desc']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore'),\n                                                  ['building_class_category'])])),\n                ('regressor', RandomForestRegressor())])preprocessor: ColumnTransformerColumnTransformer(transformers=[('num', StandardScaler(),\n                                 ['Total_Population', 'Total Housing Units',\n                                  'In Labor Force', 'Travel_Time',\n                                  'Median_HH_Income', 'Total_HH',\n                                  'ofns_desc']),\n                                ('cat', OneHotEncoder(handle_unknown='ignore'),\n                                 ['building_class_category'])])num['Total_Population', 'Total Housing Units', 'In Labor Force', 'Travel_Time', 'Median_HH_Income', 'Total_HH', 'ofns_desc']StandardScalerStandardScaler()cat['building_class_category']OneHotEncoderOneHotEncoder(handle_unknown='ignore')RandomForestRegressorRandomForestRegressor()\n\n\n\ngrid_search.best_estimator_\n\nPipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('num', StandardScaler(),\n                                                  ['Total_Population',\n                                                   'Total Housing Units',\n                                                   'In Labor Force',\n                                                   'Travel_Time',\n                                                   'Median_HH_Income',\n                                                   'Total_HH', 'ofns_desc']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore'),\n                                                  ['building_class_category'])])),\n                ('regressor',\n                 RandomForestRegressor(max_depth=30, n_estimators=300))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('num', StandardScaler(),\n                                                  ['Total_Population',\n                                                   'Total Housing Units',\n                                                   'In Labor Force',\n                                                   'Travel_Time',\n                                                   'Median_HH_Income',\n                                                   'Total_HH', 'ofns_desc']),\n                                                 ('cat',\n                                                  OneHotEncoder(handle_unknown='ignore'),\n                                                  ['building_class_category'])])),\n                ('regressor',\n                 RandomForestRegressor(max_depth=30, n_estimators=300))])preprocessor: ColumnTransformerColumnTransformer(transformers=[('num', StandardScaler(),\n                                 ['Total_Population', 'Total Housing Units',\n                                  'In Labor Force', 'Travel_Time',\n                                  'Median_HH_Income', 'Total_HH',\n                                  'ofns_desc']),\n                                ('cat', OneHotEncoder(handle_unknown='ignore'),\n                                 ['building_class_category'])])num['Total_Population', 'Total Housing Units', 'In Labor Force', 'Travel_Time', 'Median_HH_Income', 'Total_HH', 'ofns_desc']StandardScalerStandardScaler()cat['building_class_category']OneHotEncoderOneHotEncoder(handle_unknown='ignore')RandomForestRegressorRandomForestRegressor(max_depth=30, n_estimators=300)\n\n\n\ngrid_search.best_params_\n\n{'regressor__max_depth': 30, 'regressor__n_estimators': 300}\n\n\n\ndef evaluate_mape(model, X_test, y_test):\n    \"\"\"\n    Given a model and test features/targets, print out the \n    mean absolute error and accuracy\n    \"\"\"\n    # Make the predictions\n    predictions = model.predict(X_test)\n\n    # Absolute error\n    errors = abs(predictions - y_test)\n    avg_error = np.mean(errors)\n\n    # Mean absolute percentage error\n    mape = 100 * np.mean(errors / y_test)\n\n    # Accuracy\n    accuracy = 100 - mape\n\n    print(\"Model Performance\")\n    print(f\"Average Absolute Error: {avg_error:0.4f}\")\n    print(f\"Accuracy = {accuracy:0.2f}%.\")\n\n    return accuracy\n\n\n# Initialize the pipeline\nbase_model = make_pipeline(\n    transformer, RandomForestRegressor(n_estimators=20, random_state=42)\n)\n\n# Fit the training set\nbase_model.fit(x_train, y_train)\n\n# Evaluate on the test set\nbase_accuracy = evaluate_mape(base_model, x_test, y_test)# Initialize the pipeline\n\nModel Performance\nAverage Absolute Error: 0.3403\nAccuracy = 93.23%.\n\n\n\n# Initialize the pipeline\nbest_model = grid_search.best_estimator_\n\n# Fit the training set\nbest_model.fit(x_train, y_train)\n\n# Evaluate on the test set\nbest_accuracy = evaluate_mape(best_model, x_test, y_test)\n\nModel Performance\nAverage Absolute Error: 0.3354\nAccuracy = 93.31%.\n\n\n\nErrors:\nwe first test the model on the 0.3 split of 2020 data and received a test score of 0.49. This score is good enough for us to proceed with this model. For the model on historical data of 2020, we achieved an accuracy of 93.23%; whereas for the trained model, we achieved an accuracy of 93.31%. We then calculated the percentage error for each census tract and created a choropleth map to see the spatial distribution of errors. It can be seen that the error level is consistently low across most of the areas, except two or three areas as outliners. This means that our model is relatively spatially consistent.\n\n\n\n3.4 Make a data frame with percent errors and census tract info for each sale in the test set\nCreate a data frame that has the property geometries, census tract data, and percent errors for all of the sales in the test set.\n\npredictions = best_model.predict(x_test)\n\n# Absolute error\nerrors =  abs((y_test - predictions) / y_test) * 100\nerrors.head()\n\n282469    0.116377\n287738    7.274291\n328679    0.732932\n218207    3.038824\n63011     3.530113\nName: unit_sale_price, dtype: float64\n\n\n\ntest_set['percent_error'] = errors\ntest_set.head()\n\n\n\n\n\n\n\n\nborough\nneighborhood\nbuilding_class_category\ntax_class_as_of_final_roll\nblock\nlot\nbuilding_class_as_of_final\naddress\nzip_code\nresidential_units\ncommercial_units\ntotal_units\nland_square_feet\ngross_square_feet\nyear_built\ntax_class_at_time_of_sale\nbuilding_class_at_time_of\nsale_price\nsale_date\nlatitude\nlongitude\ncommunity_board\ncouncil_district\ncensus_tract\nbin\nbbl\nnta\ngeometry\nunit_sale_price\nSTATEFP\nCOUNTYFP\nTRACTCE\nGEOID\nNAME_x\nNAMELSAD\nMTFCC\nFUNCSTAT\nALAND\nAWATER\nINTPTLAT\nINTPTLON\nNAME_y\nTotal_Population\nTotal Housing Units\nIn Labor Force\nTravel_Time\nMedian_HH_Income\nTotal_HH\nstate\ncounty\ntract\nofns_desc\npercent_error\n\n\n\n\n282469\n3\nBEDFORD STUYVESANT\n03 THREE FAMILY DWELLINGS\n1\n1807\n82\nC0\n363 GATES AVE\n11216\n3\n0\n3\n2,000\n2880.0\n1899\n1\nC0\n1150000.0\n2016-05-10T00:00:00.000\n40.685994\n-73.952625\n303\n36\n243\n3050859\n3018070082\nBedford\nPOINT (-73.95262 40.68599)\n399.305556\n36\n047\n024300\n36047024300\n243\nCensus Tract 243\nG5020\nS\n154349.0\n0.0\n+40.6874555\n-073.9528560\nCensus Tract 243, Kings County, New York\n4214\n2093\n2647\n43.2\n61475\n1883\n36\n047\n024300\n45.0\n0.116377\n\n\n287738\n4\nROSEDALE\n01 ONE FAMILY DWELLINGS\n1\n13750\n176\nA2\n147-63 EDGEWOOD STREET\n11422\n1\n0\n1\n5,200\n1369.0\n1955\n1\nA2\n276500.0\n2016-05-31T00:00:00.000\n40.65567\n-73.741928\n413\n31\n664\n4292017\n4137500176\nRosedale\nPOINT (-73.74193 40.65567)\n201.972243\n36\n081\n066401\n36081066401\n664.01\nCensus Tract 664.01\nG5020\nS\n1112816.0\n103375.0\n+40.6471780\n-073.7430504\nCensus Tract 664.01, Queens County, New York\n1444\n424\n883\n52.8\n141250\n378\n36\n081\n066401\n22.0\n7.274291\n\n\n328679\n2\nBAYCHESTER\n01 ONE FAMILY DWELLINGS\n1\n4780\n46\nA5\n3020 ELY AVENUE\n10469\n1\n0\n1\n2,651\n1260.0\n1960\n1\nA5\n320000.0\n2016-11-10T00:00:00.000\n40.871916\n-73.836824\n212\n12\n46202\n2062294\n2047800046\nCo-op City\nPOINT (-73.83682 40.87192)\n253.968254\n36\n005\n046208\n36005046208\n462.08\nCensus Tract 462.08\nG5020\nS\n485072.0\n0.0\n+40.8750208\n-073.8369671\nCensus Tract 462.08, Bronx County, New York\n5586\n1494\n2748\n58.0\n73578\n1460\n36\n005\n046208\n38.0\n0.732932\n\n\n218207\nQUEENS\nFAR ROCKAWAY\n02 TWO FAMILY DWELLINGS\n1\n15790\n27\nB3\n414 BEACH 27 STREET\n11691\n2\n0\n2\n3,600\n1768.0\n1920\n1\nB3\n350000.0\n2021-03-05T00:00:00.000\n40.59785\n-73.760714\n414\n31\n99801\n4301435\n4157900027\nFar Rockaway-Bayswater\nPOINT (-73.76071 40.59785)\n197.963801\n36\n081\n099801\n36081099801\n998.01\nCensus Tract 998.01\nG5020\nS\n456707.0\n0.0\n+40.5980835\n-073.7575992\nCensus Tract 998.01, Queens County, New York\n8631\n2732\n4917\n55.3\n66532\n2634\n36\n081\n099801\n91.0\n3.038824\n\n\n63011\n4\nMASPETH\n02 TWO FAMILY DWELLINGS\n1\n2779\n44\nB2\n68-07 59TH DRIVE\n11378\n2\n0\n2\n2,000\n1836.0\n1931\n1\nB2\n965000.0\n2019-09-25T00:00:00.000\n40.721695\n-73.893983\n405\n30\n66701\n4062280\n4027790044\nMiddle Village\nPOINT (-73.89398 40.72169)\n525.599129\n36\n081\n066701\n36081066701\n667.01\nCensus Tract 667.01\nG5020\nS\n252633.0\n0.0\n+40.7218219\n-073.8913365\nCensus Tract 667.01, Queens County, New York\n3047\n1055\n1413\n43.6\n109390\n994\n36\n081\n066701\n12.0\n3.530113\n\n\n\n\n\n\n\n\nmedian_errors = test_set.groupby('GEOID')['percent_error'].median().reset_index()\n\nerror_map = merged_ct.merge(median_errors, on='GEOID')\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 6))\nerror_map.plot(column='percent_error', ax=ax, legend=True,\n               legend_kwds={'label': \"Median Percent Error by Census Tract\"},\n               cmap='OrRd')  # Choose a colormap that fits your data and preference\nax.set_axis_off()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Our Team",
    "section": "",
    "text": "Hi! I am Yuanhao Zhai, a Graduate Candidate of Master of City Planning in the University of Pennslyvania. I am really interested in the the Urban Policy and Urban Data related topic. If you want to find more information about me, please contact me by my e-mail, linkedin, or whatsapp.\n\n\n\nIn this project I was mainly responsible for data collection and analysis, code writing and website design. You are welcome to communicate with me with the specific methodology and building process of the project.\n\n\n\n\nWhatsapp acount: 267(251)3988\nE-mail: zyuanhao@upenn.edu\nLinkedIn Link: My Link"
  },
  {
    "objectID": "about.html#yuanhao-zhai",
    "href": "about.html#yuanhao-zhai",
    "title": "About Our Team",
    "section": "",
    "text": "Hi! I am Yuanhao Zhai, a Graduate Candidate of Master of City Planning in the University of Pennslyvania. I am really interested in the the Urban Policy and Urban Data related topic. If you want to find more information about me, please contact me by my e-mail, linkedin, or whatsapp.\n\n\n\nIn this project I was mainly responsible for data collection and analysis, code writing and website design. You are welcome to communicate with me with the specific methodology and building process of the project.\n\n\n\n\nWhatsapp acount: 267(251)3988\nE-mail: zyuanhao@upenn.edu\nLinkedIn Link: My Link"
  },
  {
    "objectID": "about.html#kay-li",
    "href": "about.html#kay-li",
    "title": "About Our Team",
    "section": "Kay Li",
    "text": "Kay Li\n\nAbout Me\nKaye is a second-year master of city planning student concentrating on public private development. She is interested in real estate investment and development and and urban economics.\n\n\nIn This Project\nIn this project: I was responsible for data analysis. developing and writing data storyboarding.\n\n\nContact Information\n\nPlease contact me at yuke@upenn.edu"
  },
  {
    "objectID": "analysis/index.html",
    "href": "analysis/index.html",
    "title": "Our Analysis Process",
    "section": "",
    "text": "Our Analysis Process\nThis section includes the process of project done using Jupyter notebooks. Each sub-section highlights different steps of analyses and visualizations. During our analysis process, our project can divides into Four major steps:\n\nStep One. Accessing data by using API\nStep Two. Merging data and Clean data\nStep Three\n\nOn this page, you might want to share more introductory or background information about the analyses to help guide the reader."
  }
]